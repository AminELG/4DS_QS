{"cells":[{"cell_type":"code","source":["path = \"/FileStore/tables/ji3j5lvr1493027936546/Data.csv\"\ncar_data = sc.textFile(path) "],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["car_data.count()"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["car_data.take(5)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["megane_car_data = car_data.filter(lambda x: 'Megane' in x)\nmegane_car_data.count()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["csv_car_data = car_data.map(lambda x: x.split(\";\"))"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["csv_car_data.collect()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["key_value_power = csv_car_data.map(lambda x: (x[0],float(x[6]))) \npower_by_key = key_value_power.reduceByKey(lambda x, y: x + y)\npower_by_key.collect()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["key_value_power.countByKey()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["sum_counts = key_value_power.combineByKey(\n    (lambda value: (value,1)), # the initial value, with value x and count 1\n    (lambda x, value: (x[0]+value,x[1]+1)), # how to combine a pair value with the accumulator: sum value, and increment count\n    (lambda x, y: (x[0]+y[0],x[1]+y[1])) # combine accumulators\n)\n\naverage_by_key = sum_counts.map(lambda (key, (value_sum, count)): (key, value_sum / count))\n\nprint(\"{0}\".format(average_by_key.collectAsMap()))"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":10}],"metadata":{"name":"4DS_QS_PySpark_RDD","notebookId":1875676780182349},"nbformat":4,"nbformat_minor":0}
